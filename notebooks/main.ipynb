{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xray analyzer\n",
    "In this notebook we read in the data and visualize it to see it is clean,etc.\n",
    "\n",
    "At the end the data gets written away to train the model.\n",
    "\n",
    "In early versions this will all be done in the same notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import env libraries\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Local libraries\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src import model_def as md\n",
    "from src import data_processing as dp\n",
    "from src import model_eval as me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Pytorch CUDA is installed correctly\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Device Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-sorting\n",
    "Take a test/train sampleset and put it into the respective folder, according to wanted Ns and the split between test and train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.sort_images_train_test(N=13000, delete_test_train_folder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Sorting\n",
    "\n",
    "Sort data accoridng to provided label of the given classification of the dataset (data_entry_2017.csv). This is needed for training single outcome models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join(\"..\", \"data\", \"classification\", \"Data_Entry_2017_v2020.csv\")\n",
    "image_folder = os.path.join(\"..\", \"data\", \"images_train\")\n",
    "output_folder = os.path.join(\"..\", \"data\", \"images_sorted_train\")\n",
    "\n",
    "# dp.organize_images_by_label_folder(csv_path, image_folder, output_folder)\n",
    "\n",
    "image_folder = os.path.join(\"..\", \"data\", \"images_test\")\n",
    "output_folder = os.path.join(\"..\", \"data\", \"images_sorted_test\")\n",
    "\n",
    "# dp.organize_images_by_label_folder(csv_path, image_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading\n",
    "\n",
    "Import a testset to be used in training\n",
    "\n",
    "We normalize the input since we work in grayscale. No size transformations are done since the dataset is already in 1024X1024.\n",
    "\n",
    "This is only needed for the single outcome models.\n",
    "\n",
    "TODO: figure out if we need normalizing in the multi-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_image_folder = os.path.join(\"..\", \"data\", \"images_sorted_train\")\n",
    "test_image_folder = os.path.join(\"..\", \"data\", \"images_sorted_test\")\n",
    "# print(train_image_folder)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "])\n",
    "\n",
    "\n",
    "# dataset_xrays_train = datasets.ImageFolder(root=train_image_folder, transform=transform)\n",
    "# dataset_xrays_test = datasets.ImageFolder(root=test_image_folder, transform=transform)\n",
    "\n",
    "# print(dataset_xrays_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model setup\n",
    "Below the actual model is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, data_loader, criterion, optimizer, device = md.setup_model_and_training(None, model_type=\"MultiAttention\", batch_size=16, model_mode=\"multi\", learning_rate=0.001)\n",
    "# data_loader_test = md.XrayMultiLabelDataset(os.path.join(\"data\", \"images_test\"))\n",
    "# model = md.train_model(model, data_loader, criterion, optimizer, device, num_epochs=5)\n",
    "model = md.train_multilabel_model(model, data_loader, criterion, optimizer, device, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model\n",
    "First eval against the train set, then evala gainst test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = me.evaluate_multi_model(model, data_loader, device, class_names=data_loader.dataset.get_labels())\n",
    "# me.visualize_predictions(model, data_loader, device, num_examples=5, class_names=dataset_xrays_test.classes)\n",
    "# misclass_df = me.analyze_misclassifications(model, data_loader, device, class_names=dataset_xrays_train.classes)\n",
    "# hard_examples = me.find_hard_examples(model, data_loader, device, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eval against test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader_test = md.setup_dataloader(None, path_multi=os.path.join(\"..\", \"data\", \"images_test\"), model_type=\"MultiAttention\") # dataset_xrays_test\n",
    "metrics = me.evaluate_multi_model(model, data_loader_test, device, class_names=data_loader_test.dataset.get_labels())\n",
    "# me.visualize_predictions(model, data_loader_test, device, num_examples=5, class_names=dataset_xrays_test.classes)\n",
    "# misclass_df = me.analyze_misclassifications(model, data_loader_test, device, class_names=dataset_xrays_test.classes)\n",
    "# hard_examples = me.find_hard_examples(model, data_loader_test, device, n=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
